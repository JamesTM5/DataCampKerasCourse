DataCamp Track Proposal Take Home Test
======

This is the output from the 'take home test' part of DataCamp's Project Manager
 hiring process completed by James Griffin on 30.06.19.

Design Notes:

  * There are already deep learning courses on DataCamp, so we have potential
 access to candidates for track leaders in Dan Becker and Miguel Esteban
  * Used in course 6, the Tox21 data set is potentially too old (2014).  I would
   be interested in DataCamp's policy on this.
  * Course titles aim to get click through but I don’t want to disguise the
   content insodoing.  I would want to reconsider these in relation to an
  established style guide, precedent on the platform or learner expectation.
  For example, contrast ‘Restoring a Masterpiece with Inpainting’ with ‘Using
  Convolutional Neural Networks to Predictively Reconstruct Layer Mask Content’.
  * Chapters 5-6 may be better considered as projects rather than as chapters
  depending on the volume of activity involved and the tie in with the rest of the
  track.  I would need some more clarification as to the distinction as DataCamp
  sees it in order to know whether these are satisfactory as they stand.
  * Can activities instantiate a completion time limit?  Ideally I want to simulate
  the experience of task completion in a professional environment and this is one
  way of adding to that sense of context.
  * The last course may be a little early: It is definitely an emerging aspect of
  the field, but it could be argued that including it is not yet wise in terms of
  encouraging Track completion.  I would want subject specialist advice on that.
  * I would like to note that the Learning Outcomes get less specific throughout as
  learners develop experience with the basic functions of preprocessing, building
  and training models.  This is andragogically sound across units with dependencies
  on one another but isn’t necessarily clear if one chapter is considered
  standalone.
  * I don't know if Course 2, Chapter 4, Lesson 3 is possible on the DataCamp
  platform, but given that it has huge andragogic value (I’m happy to justify
  this), I decided to leave it in.  Therefore this would need changing if cross
  validation activity is not possible or doesn’t fit well enough with the
  expectations of learners given by their experience of the rest of the platform.
  * I have tried to keep learner activity within Keras where possible, to avoid
  extra dependencies both on the course and ultimately in code.  However some
  learners may have experience of performing actions in other packages (such as pre-
  processing in Scikitlearn and Word2Vec in a purely TensorFlow context).  I am
  interested in your take on how this tends to be handled. I have made a decision
  to stay local to Keras herein.
  * I accept that a data prep exercise prior to the task I have described may not
  be expected, but I want the task to feel context groundedand for the user to
  begin working on something that is likely familiar to them.  It also served to
  introduce some Keras native pre-prep activity in preparation for the next chapter.
  * For the course task, I accept that it may not be optimal to go with a fully
  connected layer structure with this dataset, but it is obviously simplified and I
  am expecting the user to be able to recognise that this is the case to test their
  knowledge of syntax and procedure.  I would like to know how DataCamp tends to
  handle these tradeoffs in learning design.
